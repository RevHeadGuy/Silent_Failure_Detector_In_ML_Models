# ğŸ” Silent Failure Detector

A production-style machine learning monitoring system designed to detect silent failures in ML models by tracking prediction drift, feature drift, and behavioral degradation over time â€” without relying on immediate labels.

The system combines statistical drift detection, severity classification, alerting, and an interactive dashboard to ensure long-term model reliability.

# ğŸš€ Key Capabilities

1. Prediction Drift Detection : Detects changes in model prediction behavior using distribution-based metrics

2. Feature-Level Drift Monitoring : Tracks individual feature drift using PSI (Population Stability Index) and KL Divergence

3. Shadow Model Comparison : Compares production model predictions with a shadow model to approximate concept drift

4. Interactive Monitoring Dashboard : Streamlit dashboard with rolling window analysis and visualizations

5. Alert Routing System : Configurable alerting based on drift severity (console, email, Slack)

6. Severity Classification : Automatic classification of drift severity: LOW, MEDIUM, HIGH

7. Baseline Behavior Management : Captures and stores healthy baseline behavior for future comparisons

# ğŸ§  Why Silent Failure Detection?

Traditional ML systems often fail silently:

1. The model keeps running

2. No exceptions are thrown

3. Predictions slowly become unreliable

This project detects those failures early, before accuracy drops or business impact occurs.

# ğŸ“ Project Structure

silent_failure_detector/
â”œâ”€â”€ alerts/                 # Alert generation and routing
â”‚   â”œâ”€â”€ alert_engine.py
â”‚   â””â”€â”€ alert_router.py
â”œâ”€â”€ baseline/               # Stored baseline and monitoring outputs
â”‚   â”œâ”€â”€ feature_drift_metrics.csv
â”‚   â”œâ”€â”€ prediction_drift_metrics.csv
â”‚   â”œâ”€â”€ shadow_model_predictions.csv
â”‚   â””â”€â”€ save_baseline_predictions.py
â”œâ”€â”€ config/                 # Configuration management
â”‚   â”œâ”€â”€ config.yaml
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â””â”€â”€ thresholds.py
â”œâ”€â”€ dashboard/              # Streamlit dashboard
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ charts.py
â”‚   â”œâ”€â”€ layout.py
â”‚   â””â”€â”€ styles.css
â”œâ”€â”€ data/                   # Input dataset
â”‚   â””â”€â”€ machine_data.csv
â”œâ”€â”€ model/                  # Model training
â”‚   â””â”€â”€ train_model.py
â”œâ”€â”€ monitoring/             # Drift detection logic
â”‚   â”œâ”€â”€ concept_drift.py
â”‚   â”œâ”€â”€ drift_metrics.py
â”‚   â”œâ”€â”€ drift_severity.py
â”‚   â”œâ”€â”€ drift_trend.py
â”‚   â”œâ”€â”€ feature_monitor.py
â”‚   â”œâ”€â”€ prediction_drift.py
â”‚   â”œâ”€â”€ retraining_trigger.py
â”‚   â”œâ”€â”€ rolling_window.py
â”‚   â”œâ”€â”€ root_cause.py
â”‚   â”œâ”€â”€ severity.py
â”‚   â””â”€â”€ shadow_model.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ load_data.py
â””â”€â”€ main.py                 # Pipeline entry point
